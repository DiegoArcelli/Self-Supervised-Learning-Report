Contrastive Predictive Coding (CPC) \cite{oord2018representation} is a method which has been thought actually not only for the computer vision field, but it can be applied also to other domains like audio and natural language. The idea of the method is to train a model that learns the representation of the data by predicting the representation of future observations from the past ones. When applied to image processing CPC works as follows: from an image we extract a certain number of overlapping crops of a fixed size and we organize those crops in a grid. If $x_{i,j}$ is the crop in position $i, j$ of the grid, then we use an encoder $f_\theta(\cdot)$ to encode each crop of the grid into a single vector $z_{i,j} = f_\theta(x_{i,j})$. After that a second auto-regressive model $g_\phi(\cdot)$ is used to compute $c_{i,j} = g_\phi(\{z_{u,v}\}_{u\le i, v})$ that is a context vector that summarizes the feature in the previous rows but in the same column of $z_{i,j}$. The predictive tasks consists of predicting a feature vectors $z_{i+k,j}$ from the context vector $c_{i,j}$, where $k > 0$, using a linear model $W_k$ computing $\hat{z}_{i+k,j} = W_kc_{i,j}$. To measure the quality of the prediction a contrastive loss is employed:
\[ \mathcal{L}_{\text{CPC}} = -\sum_{i,j,k}\log p(z_{i+k,j}|\hat{z}_{i+k,j}, \{z_l\}) = -\sum_{i,j,k}\log \frac{\exp(\hat{z}^T_{i+k,j}z_{i+k,j})}{\exp(\hat{z}^T_{i+k,j}z_{i+k,j}) + \sum_l \exp(\hat{z}^T_{i+k,j}z_l)}\]
where $\{z_l\}$ is the set of negative samples which is composed by taking crops from different location of the grid. In the paper they prove formally that minimizing this loss is equivalent of maximizing the mutual information between $c_{i,j}$ and $x_{i+k,j}$, obtaining the bound:
\[ I(x_{i+k,j}, c_{i,j}) \ge \log(N) - \mathcal{L}_{CPC}\]
where $N$ is the number of negative examples used in the loss. After having trained the whole architecture, for the fine-tuning on downstream tasks we keep only the encoder network $f_\theta(\cdot)$ and use it as feature extractor for a classification model, which is then trained on a supervised task. For the encoder $f_\theta$ any CNN can be applied, in the paper the authors used a ResNet101, while for the auto-regressive model $g_\phi$ they used a PixelCNN.

In \cite{henaff2020data} the authors proposes CPC-v2, an improved version of CPC where essentially they do some modification of some training details like applying augmentation to the crops individually, increasing the crops sizes, using layer normalization instead of batch normalization and some other minors modifications, but the backbone of the method remains the same.