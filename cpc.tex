Contrastive Predictive Coding (CPC) \cite{oord2018representation} is a method which has been thought actually not only for the computer vision field, but it can be applied also to other domains like audio and natural language. The idea of the method is to train a model that learns representation of the data by predicting the representation of future observations from the past ones. The intuition of the authors is that when using powerful generative models for predicting high-dimensional data, the model wastes capacity in modeling relationships of data $x$ ignoring the context $c$, so modeling $p(x|c)$ directly it's not optimal for the purpose of extracting shared information between $x$ and $y$. When we instead predict a future information, the future $x$ and the context $c$ are encoded in a vector representation using a non-linear mapping that  maximally preserves the mutual information between $x$ and $c$, so that we can extract the underlying latent variables that $x$ and $c$ have in common. When applied to image processing CPC works as follows: from an image we extract a certain number of overlapping crops of a fixed size and we organize those crops in a grid. If $x_{i,j}$ is the crop in position $i, j$ of the grid, then we use and encoder $f_\theta(\cdot)$ to encode each crop of the grid into a single vector $z_{i,j} = f_\theta(x_{i,j})$. After that a second auto-regressive model $g_\phi(\cdot)$ is used to compute $c_{i,j} = g_\phi(\{z_{u,v}\}_{u\le i, v})$ that is a context vector that summarizes the feature in the previous rows but in the same column of $z_{i,j}$. The predictive tasks consists of predicting a feature vectors $z_{i+k,j}$ from the context vector $c_{i,j}$, where $k > 0$, using a linear model $W_k$ computing $\hat{z}_{i+k,j} = W_kc_{i,j}$. To measure the quality of the prediction a contrastive loss is employed:
\[ \mathcal{L}_{\text{CPC}} = -\sum_{i,j,k}\log p(z_{i+k,j}|\hat{z}_{i+k,j}, \{z_l\}) = -\sum_{i,j,k}\log \frac{\exp(\hat{z}^T_{i+k,j}z^T_{i+k,j})}{\exp(\hat{z}^T_{i+k,j}z^T_{i+k,j}) + \sum_l \exp(\hat{z}^T_{i+k,j}z^T_l)}\]
where $\{z_l\}$ is the set of negative samples which is composed by taking crops from different location of the grid. In the paper they prove formally that minimizing this loss is equivalent of maximizing the mutual information between $c_{i,j}$ and $x_{i+k,j}$, obtaining the bound:
\[ I(x_{i+k,j}, c_{i,j}) \ge \log(N) - \mathcal{L}_{CPC}\]
where $N$ is the number of negative examples used in the loss. After having trained the whole architecture, for the fine-tuning on downstream tasks we keep only the encoder network $f_\theta(\cdot)$ and use it as feature extractor for a classification model, which is then trained on a supervised task.

For the encoder $f_\theta$ any CNN can be applied, in the paper the authors used a ResNet101, while for the auto-regressive model $g_\phi$ they used a PixelCNN.