In this section the five methods we have explained will be compared in term of performances, in addition also two other methods which have been explored during the lectures will be considered, SimCLR \cite{chen2020simple} and BYOL \cite{grill2020bootstrap}. As we already said in the previous sections, the way in which we evaluate SSL methods is by evaluating how downstream tasks perform after the SSL phase. Of course the evaluation on the downstream task might depends by many factors: the chosen dataset, the type of the architecture, the network used for the encoding, the hyper-parameters used for the methods and so on. In this section I tried to used the results taken from the papers of the cited methods and from this survey \cite{technologies9010002}, in order to have a fair comparison of the performances of all the methods.

In table \ref{tab:imagenet-top1-5-acc-comp} we report the top-1 and top-5 accuracy of the considered methods when tested for classification on the ImageNet dataset and also the performances of a supervised model trained directly without SSL. All the methods uses as feature extractor a ResNet50 and the fine-tuning the SSL model is frozen and we train a linear classifier. SWAV and BYOL are by far the two best performing models even if they do not reach the top-1 accuracy of the supervised model.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|cc|}
		\hline
		\multicolumn{1}{|c|}{\textbf{Method}} & \textbf{Architecture} & \multicolumn{2}{c|}{\textbf{ImageNet}} \\
		\multicolumn{1}{|c|}{} &  & Top1 & Top5 \\
		\hline
		Supervised & ResNet50 & 76.5 & - \\
		\hline
		PIRL & ResNet50 & 63.6 & - \\
		CPCv2 & ResNet50 & 63.8 & 85.3 \\
		CMC & ResNet50  & 66.2 & 87 \\
		SimCLR & ResNet50 & 69.3 & 89.0 \\
		MoCov2 & ResNet50 & 71.1 & - \\
		BYOL & ResNet50  & 74.3 & 91.6 \\ 
		SwAV & ResNet50 & 75.3 & - \\
		\hline
\end{tabular}
	\caption{Accuracy of the SSL methods using linear probing for fine-tuning}
	\label{tab:imagenet-top1-5-acc-comp}
\end{table}


Table \ref{tab:imagenet-1-perc-semisup} shows the performances of the methods in semi-supervised learning scenario. Basically after having performed the SSL models before evaluating the on the classification task on ImageNet we first fine-tune the model using in one case the 1\% and in the other case the 10\% of the data. We report also same version of the same model with different encoder sizes. If we only look at the models that use the ResNet50 the raking of the model is the same that we obtained in the case of the linear probing.

\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|cc|cc|}
		\hline
		\multicolumn{1}{|c|}{\textbf{Method}} & \textbf{Architecture} & \multicolumn{2}{c|}{\textbf{ImageNet 1\%}} & \multicolumn{2}{c|}{\textbf{ImageNet 10\%}} \\
		\multicolumn{1}{|c|}{} &  & Top1 & Top5 & Top1 & Top5  \\
		\hline
		Supervised & ResNet50 & 25.4 & 48.4 & 56.4 & 80.4 \\
		PIRL & ResNet50 & 30.7 & 57.2  & 60.4 & 83.8 \\
		SimCLR & ResNet50 & 48.3 & 75.5  & 65.6 & 87.8 \\
		BYOL & ResNet50  & 53.2 & 78.4  & 68.8 & 89.0 \\ 
		SwAV & ResNet50 & 53.9 & 78.5  & 70.2 & 89.9 \\
		CPCv2 & ResNet161 & - & 77.9 & - & 91.2 \\
		SimCLR & ResNet50 (4$\times$) & 63.0 & 85.8 & 74.4 & 92.6 \\
		BYOL & ResNet50 (2$\times$) & 71.2 & 89.5 & 77.7 & 93.7 \\
		\hline
	\end{tabular}
	\caption{Accuracy of semi }
	\label{tab:imagenet-1-perc-semisup}
\end{table}


\begin{table}[H]
	\centering
	\begin{tabular}{l|ccc||ccc|}
		\cline{2-7}
		\multicolumn{1}{c|}{\textbf{}} & \multicolumn{3}{c||}{\textbf{Linear classification}} & \multicolumn{3}{c|}{\textbf{Object detection}} \\ \cline{2-7} 
		& \multicolumn{1}{l|}{Places205} & \multicolumn{1}{l|}{VOC07} & \multicolumn{1}{l||}{iNat18} & \multicolumn{1}{l|}{VOC07+12} & \multicolumn{1}{l|}{COCO} & \multicolumn{1}{l|}{COCO} \\ \hline
		\multicolumn{1}{|l|}{Supervised} & \multicolumn{1}{c|}{53.2} & \multicolumn{1}{c|}{87.5} & 46.7 & \multicolumn{1}{c|}{81.3} & \multicolumn{1}{c|}{39.7} & 40.8 \\ \hline
		\multicolumn{1}{|l|}{PIRL} & \multicolumn{1}{c|}{49.8} & \multicolumn{1}{c|}{81.1} & 34.1 & \multicolumn{1}{c|}{80.7} & \multicolumn{1}{c|}{-} & - \\ \hline
		\multicolumn{1}{|l|}{SimCLR} & \multicolumn{1}{c|}{53.3} & \multicolumn{1}{c|}{86.4} & 36.2 & \multicolumn{1}{c|}{-} & \multicolumn{1}{c|}{-} & - \\ \hline
		\multicolumn{1}{|l|}{MoCov2} & \multicolumn{1}{c|}{52.9} & \multicolumn{1}{c|}{87.1} & 38.9 & \multicolumn{1}{c|}{82.5} & \multicolumn{1}{c|}{39.8} & 42.0 \\ \hline
		\multicolumn{1}{|l|}{SWAV} & \multicolumn{1}{c|}{56.7} & \multicolumn{1}{c|}{88.9} & 48.6 & \multicolumn{1}{c|}{82.6} & \multicolumn{1}{c|}{41.6} & 42.1 \\ \hline
	\end{tabular}
	\caption{Result after fine-tuning on 1\% of the data of ImageNet}
	\label{tab:object-detection-swav}
\end{table}

\begin{comment}
\begin{table}[H]
	\centering
	\begin{tabular}{l|ccc||ccc||ccc|}
		\cline{2-10}
		& \multicolumn{3}{c||}{\textbf{VOC 07+12 detection}} & \multicolumn{3}{c||}{\textbf{COCO detection}} & \multicolumn{3}{c|}{\textbf{COCO instance seg.}} \\ \hline
		\multicolumn{1}{|l||}{\textbf{Method}} & \multicolumn{1}{c|}{AP\_50} & \multicolumn{1}{c|}{AP} & AP$_{75}$ & \multicolumn{1}{c|}{AP\_50} & \multicolumn{1}{c|}{AP} & AP\_75 & \multicolumn{1}{c|}{AP\_50} & \multicolumn{1}{c|}{AP} & AP\_75 \\ \hline
		\multicolumn{1}{|l||}{MoCov2} & \multicolumn{1}{c|}{82.7} & \multicolumn{1}{c|}{57.9} & 64.5 & \multicolumn{1}{c|}{61.0} & \multicolumn{1}{c|}{41.1} & 44.8 & \multicolumn{1}{c|}{57.7} & \multicolumn{1}{c|}{35.8} & 38.4 \\ \hline
		\multicolumn{1}{|l||}{BYOL} & \multicolumn{1}{c|}{82.7} & \multicolumn{1}{c|}{56.7} & 63.0 & \multicolumn{1}{c|}{61.1} & \multicolumn{1}{c|}{40.9} & 44.5 & \multicolumn{1}{c|}{57.6} & \multicolumn{1}{c|}{35.5} & 37.8 \\ \hline
		\multicolumn{1}{|l||}{SWAV} & \multicolumn{1}{c|}{82.3} & \multicolumn{1}{c|}{55.6} & 61.9 & \multicolumn{1}{c|}{61.4} & \multicolumn{1}{c|}{40.7} & 43.7 & \multicolumn{1}{c|}{57.6} & \multicolumn{1}{c|}{35.4} & 37.4 \\ \hline
	\end{tabular}
	\caption{Result after fine-tuning on 1\% of the data of ImageNet}
	\label{tab:object-detection-comp}
\end{table}
\end{comment}

\begin{comment}
\begin{table}[H]
	\centering
	\begin{tabular}{|l|l|c|c|}
		\hline
		\multicolumn{1}{|c|}{Method} & \multicolumn{1}{c|}{Architecture} & AP\_50 & mIoU \\ \hline
		Supervised & ResNet50 & 74.4 & 74.4 \\ \hline
		MoCo & ResNet50 & 74.9 & 72.5 \\ \hline
		CPC & ResNet161 & 76.6 & - \\ \hline
		SimCLR & ResNet50 & 75.2 & 75.2 \\ \hline
		BYOL & ResNet50 & 77.5 & 76.3 \\ \hline
	\end{tabular}
	\caption{Result after fine-tuning on 1\% of the data of ImageNet}
	\label{tab:object-detection-byol}
\end{table}
\end{comment}
\begin{comment}
Figure \ref{fig:imagenet-top1-acc-comp} shows the accuracy of SSL methods with encoders of different parameters sizes in image classification for ImageNet, and it highlights that the number of parameters of the model is important to get high performances. For instances CPCv2 with a large encoder performs better that MoCo and SimCLR with a smaller encoder.
\begin{figure}[H]
	\centering
	\includegraphics[width=10cm]{./images/imagenet-top1-acc-comp.png}
	\caption{Top-1 classification accuracy different contrastive learning methods with the number of parameters of the models}
	\label{fig:imagenet-top1-acc-comp}
\end{figure}
\end{comment}