In conclusion, this work explored various self-supervised learning methods for computer vision. The general framework of self-supervised learning was discussed, highlighting the advantages of learning from unlabeled data and the potential of transferring learned representations to downstream tasks. Different self-supervised learning methods were described in detail and compared. The empirical results showed that the two best performing models on the downstream tasks are BYOL and SWAV, while CPC, CMC and PIRL are the worst performer. SimCLR and MoCo are not as good as BYOL and SWAV but still better than the worst three.